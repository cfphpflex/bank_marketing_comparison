# -*- coding: utf-8 -*-
"""bank_marketing_model_comparison.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WJu47gob7gyW7Pcl5HH7ByqGMRWbf4D4
"""

#get libs
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from imblearn.over_sampling import SMOTE


import time

# Load dataset
data_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip"
!wget -q $data_url -O bank.zip
!unzip -o bank.zip

df = pd.read_csv("bank.csv", sep=';')
df.head()

## Data Exploration and Cleaning
print(df.info())
print(df.isnull().sum())

df.replace('unknown', pd.NA, inplace=True)
df.replace('unknown', pd.NA, inplace=True)
print(df.isna().sum())
# Optional: Drop rows or impute after checking counts

# feature engineering and cleanup
for col in ['balance', 'age']:
    upper = df[col].quantile(0.99)
    lower = df[col].quantile(0.01)
    df[col] = np.clip(df[col], lower, upper)
    # df[col] = np.where(df[col] > upper, upper, df[col])

# df['age_group'] = pd.cut(df['age'], bins=[18, 30, 40, 50, 60, 100], labels=['18-30', '31-40', '41-50', '51-60', '60+'])
df['age_group'] = pd.cut(df['age'], bins=[18, 30, 40, 50, 60, 100], labels=['18-30', '31-40', '41-50', '51-60', '60+'])
df['has_prev_contact'] = (df['previous'] > 0).astype(int)


for col in ['job_technician', 'job_unemployed', 'marital_married', 'marital_single', 'education_secondary']:
    df[col] = df[col].astype('category')

df = df.drop_duplicates()

# Plot
sns.boxplot(data=df[['age',  'balance']])
plt.show()

# Define features and target
X = df_encoded.drop('y', axis=1)
y = df_encoded['y']

#Class Imbalance MitigationClass weighting:

LogisticRegression(class_weight='balanced')

# Label Encoding for binary target variable
le = LabelEncoder()
df['y'] = le.fit_transform(df['y'])

# Convert categorical variables to dummies
df_encoded = pd.get_dummies(df.drop('y', axis=1), drop_first=True)
df_encoded['y'] = df['y']

# X, y data
X = df_encoded.drop('y', axis=1)
y = df_encoded['y']

# Encode binary target
le = LabelEncoder()
df['y'] = le.fit_transform(df['y'])  # 'yes' → 1, 'no' → 0

# One-hot encode categorical features
df_encoded = pd.get_dummies(df.drop('y', axis=1), drop_first=True)
df_encoded['y'] = df['y']

# Define features and target
X = df_encoded.drop('y', axis=1)
y = df_encoded['y']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Apply SMOTE oversampling
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

## Modeling and Evaluation
models = {
    "KNN": KNeighborsClassifier(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "SVM": SVC(probability=True)
}

#Score model
results = {}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    score = cross_val_score(model, X_train_scaled, y_train, cv=5).mean()
    results[name] = {
        "CV Score": score,
        "Report": classification_report(y_test, y_pred, output_dict=True),
        "Confusion Matrix": confusion_matrix(y_test, y_pred)
    }

#Grid Search Ea. Model Find best params
# 1. KNN
knn_params = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance']
}
knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy')
knn_grid.fit(X_train_scaled, y_train)
print("Best KNN params:", knn_grid.best_params_)
print("KNN best CV score:", knn_grid.best_score_)
print("KNN test score:", knn_grid.score(X_test_scaled, y_test))


# 2. Logistic Regression
logreg_params = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l2'],
    'solver': ['lbfgs', 'liblinear']
}
logreg_grid = GridSearchCV(LogisticRegression(max_iter=1000), logreg_params, cv=5, scoring='accuracy')
logreg_grid.fit(X_train_scaled, y_train)
print("Best Logistic Regression params:", logreg_grid.best_params_)
print("Logistic Regression best CV score:", logreg_grid.best_score_)
print("Logistic Regression test score:", logreg_grid.score(X_test_scaled, y_test))

# 3. Decision Tree
tree_params = {
    'max_depth': [2, 4, 6, 8, 10],
    'min_samples_split': [2, 5, 10]
}
tree_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_params, cv=5, scoring='accuracy')
tree_grid.fit(X_train_scaled, y_train)
print("Best Decision Tree params:", tree_grid.best_params_)
print("Decision Tree best CV score:", tree_grid.best_score_)
print("Decision Tree test score:", tree_grid.score(X_test_scaled, y_test))

# 4. SVM
svm_params = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}
svm_grid = GridSearchCV(SVC(probability=True), svm_params, cv=5, scoring='accuracy')
svm_grid.fit(X_train_scaled, y_train)
print("Best SVM params:", svm_grid.best_params_)
print("SVM best CV score:", svm_grid.best_score_)
print("SVM test score:", svm_grid.score(X_test_scaled, y_test))

#SVM Confusion Matrics
from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_estimator(svm_grid, X_test_scaled, y_test)
plt.title("SVM - Confusion Matrix")
plt.show()

from sklearn.metrics import roc_curve, auc

y_probs = svm_grid.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, label=f"SVM (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("SVM - ROC Curve")
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import precision_recall_curve, average_precision_score

precision, recall, _ = precision_recall_curve(y_test, y_probs)
ap_score = average_precision_score(y_test, y_probs)

plt.plot(recall, precision, label=f'SVM (AP = {ap_score:.2f})')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("SVM - Precision-Recall Curve")
plt.legend()
plt.grid(True)
plt.show()

# Print summary
for name, metrics in results.items():
    print(f"\nModel: {name}")
    print(f"Cross-Validation Score: {metrics['CV Score']:.4f}")
    print("Classification Report:")
    print(pd.DataFrame(metrics['Report']).transpose())
    print("Confusion Matrix:")
    print(metrics['Confusion Matrix'])

# Tree, HyperParams & fit
# Example: A small tree to demonstrate underfitting/overfitting control
tree_overfit = DecisionTreeClassifier(max_depth=2, min_samples_split=2, min_samples_leaf=1, random_state=42)
tree_overfit.fit(X_train, y_train)

# SCORE
train_acc = tree_overfit.score(X_train, y_train)
test_acc = tree_overfit.score(X_test, y_test)
print(f"\nDecision Tree (depth=2) Train Accuracy: {train_acc:.4f}")
print(f"Decision Tree (depth=2) Test Accuracy: {test_acc:.4f}")

# ROC Curve for 2nd best Model: Logistic Regression   Cross-Validation Score: 0.8961
best_model = LogisticRegression(max_iter=1000)
best_model.fit(X_train_scaled, y_train)
y_probs = best_model.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_probs)

# PLot ROC for Logistict Regression
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='Logistic Regression')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.show()

Essential step for logistic regression, SVM, etc.

df = pd.get_dummies(df, drop_first=True)

Prints the proportion of class labels in y
print(df['y'].value_counts(normalize=True))  # Class balance
print(df.corr())

# print(df.describe())
print(df['y'].value_counts())
print(df.corr(numeric_only=True))
for col in ['job_technician', 'job_unemployed', 'marital_married', 'marital_single', 'education_secondary']:
    print(df[col].value_counts())



# job_technician Bar plot example
sns.countplot(x='job_technician', hue='y', data=df)
plt.title('job_technician vs y')
plt.show()



# job_unemployed Bar plot example
sns.countplot(x='job_unemployed', hue='y', data=df)
plt.title('job_unemployed vs y')
plt.show()


# marital_married Bar plot example
sns.countplot(x='marital_married', hue='y', data=df)
plt.title('marital_married vs y')
plt.show()


# marital_single Bar plot example
sns.countplot(x='marital_single', hue='y', data=df)
plt.title('marital_single vs y')
plt.show()

